(dp0
S'transcript'
p1
(lp2
(lp3
VI work with a bunch of mathematicians, philosophers and computer scientists,
p4
aVand we sit around and think about the future of machine intelligence,
p5
aVamong other things.
p6
aVSome people think that some of these things are sort of science fiction-y,
p7
aVfar out there, crazy.
p8
aVBut I like to say,
p9
aVokay, let's look at the modern human condition.
p10
aV(Laughter)
p11
aVThis is the normal way for things to be.
p12
aa(lp13
VBut if we think about it,
p14
aVwe are actually recently arrived guests on this planet,
p15
aVthe human species.
p16
aVThink about if Earth was created one year ago,
p17
aVthe human species, then,  would be 10 minutes old.
p18
aVThe industrial era started two seconds ago.
p19
aVAnother way to look at this is to think of world GDP over the last 10,000 years,
p20
aVI've actually taken the trouble to plot this for you in a graph.
p21
aVIt looks like this.
p22
aV(Laughter)
p23
aVIt's a curious shape for a normal condition.
p24
aVI sure wouldn't want to sit on it.
p25
aV(Laughter)
p26
aa(lp27
VLet's ask ourselves, what is the cause of this current anomaly?
p28
aVSome people would say it's technology.
p29
aVNow it's true, technology has accumulated through human history,
p30
aVand right now, technology advances extremely rapidly \u2014
p31
aVthat is the proximate cause,
p32
aVthat's why we are currently  so very productive.
p33
aVBut I like to think back further  to the ultimate cause.
p34
aa(lp35
VLook at these two highly distinguished gentlemen:
p36
aVWe have Kanzi \u2014
p37
aVhe's mastered 200 lexical tokens, an incredible feat.
p38
aVAnd Ed Witten unleashed the second superstring revolution.
p39
aVIf we look under the hood,  this is what we find:
p40
aVbasically the same thing.
p41
aVOne is a little larger,
p42
aVit maybe also has a few tricks in the exact way it's wired.
p43
aVThese invisible differences cannot be too complicated, however,
p44
aVbecause there have only been 250,000 generations
p45
aVsince our last common ancestor.
p46
aVWe know that complicated mechanisms take a long time to evolve.
p47
aVSo a bunch of relatively minor changes
p48
aVtake us from Kanzi to Witten,
p49
aVfrom broken-off tree branches to intercontinental ballistic missiles.
p50
aa(lp51
VSo this then seems pretty obvious that everything we've achieved,
p52
aVand everything we care about,
p53
aVdepends crucially on some relatively minor changes that made the human mind.
p54
aVAnd the corollary, of course, is that any further changes
p55
aVthat could significantly change the substrate of thinking
p56
aVcould have potentially  enormous consequences.
p57
aa(lp58
VSome of my colleagues  think we're on the verge
p59
aVof something that could cause a profound change in that substrate,
p60
aVand that is machine superintelligence.
p61
aVArtificial intelligence used to be about putting commands in a box.
p62
aVYou would have human programmers
p63
aVthat would painstakingly  handcraft knowledge items.
p64
aVYou build up these expert systems,
p65
aVand they were kind of useful  for some purposes,
p66
aVbut they were very brittle, you couldn't scale them.
p67
aVBasically, you got out only what you put in.
p68
aVBut since then,
p69
aVa paradigm shift has taken place in the field of artificial intelligence.
p70
aa(lp71
VToday, the action is really  around machine learning.
p72
aVSo rather than handcrafting knowledge representations and features,
p73
aVwe create algorithms that learn, often from raw perceptual data.
p74
aVBasically the same thing that the human infant does.
p75
aVThe result is A.I. that is not limited to one domain \u2014
p76
aVthe same system can learn to translate  between any pairs of languages,
p77
aVor learn to play any computer game on the Atari console.
p78
aVNow of course,
p79
aVA.I. is still nowhere near having the same powerful, cross-domain
p80
aVability to learn and plan as a human being has.
p81
aVThe cortex still has some  algorithmic tricks
p82
aVthat we don't yet know how to match in machines.
p83
aa(lp84
VSo the question is,
p85
aVhow far are we from being able to match those tricks?
p86
aVA couple of years ago,
p87
aVwe did a survey of some of the world's  leading A.I. experts,
p88
aVto see what they think, and one of the questions we asked was,
p89
aV"By which year do you think there is a 50 percent probability
p90
aVthat we will have achieved  human-level machine intelligence?"
p91
aVWe defined human-level here  as the ability to perform
p92
aValmost any job at least as well as an adult human,
p93
aVso real human-level, not just within some limited domain.
p94
aVAnd the median answer was 2040 or 2050,
p95
aVdepending on precisely which  group of experts we asked.
p96
aVNow, it could happen much, much later, or sooner,
p97
aVthe truth is nobody really knows.
p98
aa(lp99
VWhat we do know is that the ultimate  limit to information processing
p100
aVin a machine substrate lies far outside  the limits in biological tissue.
p101
aVThis comes down to physics.
p102
aVA biological neuron fires, maybe,  at 200 hertz, 200 times a second.
p103
aVBut even a present-day transistor operates at the Gigahertz.
p104
aVNeurons propagate slowly in axons, 100 meters per second, tops.
p105
aVBut in computers, signals can travel at the speed of light.
p106
aVThere are also size limitations,
p107
aVlike a human brain has  to fit inside a cranium,
p108
aVbut a computer can be the size of a warehouse or larger.
p109
aVSo the potential for superintelligence  lies dormant in matter,
p110
aVmuch like the power of the atom  lay dormant throughout human history,
p111
aVpatiently waiting there until 1945.
p112
aVIn this century,
p113
aVscientists may learn to awaken the power of artificial intelligence.
p114
aVAnd I think we might then see an intelligence explosion.
p115
aa(lp116
VNow most people, when they think about what is smart and what is dumb,
p117
aVI think have in mind a picture roughly like this.
p118
aVSo at one end we have the village idiot,
p119
aVand then far over at the other side
p120
aVwe have Ed Witten, or Albert Einstein, or whoever your favorite guru is.
p121
aVBut I think that from the point of view of artificial intelligence,
p122
aVthe true picture is actually probably more like this:
p123
aVAI starts out at this point here, at zero intelligence,
p124
aVand then, after many, many  years of really hard work,
p125
aVmaybe eventually we get to mouse-level artificial intelligence,
p126
aVsomething that can navigate  cluttered environments
p127
aVas well as a mouse can.
p128
aVAnd then, after many, many more years of really hard work, lots of investment,
p129
aVmaybe eventually we get to chimpanzee-level artificial intelligence.
p130
aVAnd then, after even more years  of really, really hard work,
p131
aVwe get to village idiot  artificial intelligence.
p132
aVAnd a few moments later,  we are beyond Ed Witten.
p133
aVThe train doesn't stop at Humanville Station.
p134
aVIt's likely, rather, to swoosh right by.
p135
aa(lp136
VNow this has profound implications,
p137
aVparticularly when it comes  to questions of power.
p138
aVFor example, chimpanzees are strong \u2014
p139
aVpound for pound, a chimpanzee is about twice as strong as a fit human male.
p140
aVAnd yet, the fate of Kanzi  and his pals depends a lot more
p141
aVon what we humans do than on what the chimpanzees do themselves.
p142
aVOnce there is superintelligence,
p143
aVthe fate of humanity may depend on what the superintelligence does.
p144
aVThink about it:
p145
aVMachine intelligence is the last invention that humanity will ever need to make.
p146
aVMachines will then be better  at inventing than we are,
p147
aVand they'll be doing so  on digital timescales.
p148
aVWhat this means is basically a telescoping of the future.
p149
aVThink of all the crazy technologies  that you could have imagined
p150
aVmaybe humans could have developed in the fullness of time:
p151
aVcures for aging, space colonization,
p152
aVself-replicating nanobots or uploading of minds into computers,
p153
aVall kinds of science fiction-y stuff
p154
aVthat's nevertheless consistent  with the laws of physics.
p155
aVAll of this superintelligence could  develop, and possibly quite rapidly.
p156
aa(lp157
VNow, a superintelligence with such  technological maturity
p158
aVwould be extremely powerful,
p159
aVand at least in some scenarios, it would be able to get what it wants.
p160
aVWe would then have a future that would be shaped by the preferences of this A.I.
p161
aVNow a good question is, what are those preferences?
p162
aVHere it gets trickier.
p163
aVTo make any headway with this,
p164
aVwe must first of all avoid anthropomorphizing.
p165
aVAnd this is ironic because  every newspaper article
p166
aVabout the future of A.I. has a picture of this:
p167
aVSo I think what we need to do is to conceive of the issue more abstractly,
p168
aVnot in terms of vivid Hollywood scenarios.
p169
aa(lp170
VWe need to think of intelligence  as an optimization process,
p171
aVa process that steers the future into a particular set of configurations.
p172
aVA superintelligence is a really strong optimization process.
p173
aVIt's extremely good at using  available means to achieve a state
p174
aVin which its goal is realized.
p175
aVThis means that there is no necessary connection between
p176
aVbeing highly intelligent in this sense,
p177
aVand having an objective that we humans would find worthwhile or meaningful.
p178
aa(lp179
VSuppose we give an A.I. the goal  to make humans smile.
p180
aVWhen the A.I. is weak, it performs useful or amusing actions
p181
aVthat cause its user to smile.
p182
aVWhen the A.I. becomes superintelligent,
p183
aVit realizes that there is a more effective way to achieve this goal:
p184
aVtake control of the world
p185
aVand stick electrodes into the facial muscles of humans
p186
aVto cause constant, beaming grins.
p187
aVAnother example,
p188
aVsuppose we give A.I. the goal to solve a difficult mathematical problem.
p189
aVWhen the A.I. becomes superintelligent,
p190
aVit realizes that the most effective way  to get the solution to this problem
p191
aVis by transforming the planet into a giant computer,
p192
aVso as to increase its thinking capacity.
p193
aVAnd notice that this gives the A.I.s an instrumental reason
p194
aVto do things to us that we might not approve of.
p195
aVHuman beings in this model are threats,
p196
aVwe could prevent the mathematical problem from being solved.
p197
aa(lp198
VOf course, perceivably things won't  go wrong in these particular ways;
p199
aVthese are cartoon examples.
p200
aVBut the general point here is important:
p201
aVif you create a really powerful optimization process
p202
aVto maximize for objective x,
p203
aVyou better make sure  that your definition of x
p204
aVincorporates everything you care about.
p205
aVThis is a lesson that's also taught in many a myth.
p206
aVKing Midas wishes that everything he touches be turned into gold.
p207
aVHe touches his daughter,  she turns into gold.
p208
aVHe touches his food, it turns into gold.
p209
aVThis could become practically relevant,
p210
aVnot just as a metaphor for greed,
p211
aVbut as an illustration of what happens
p212
aVif you create a powerful optimization process
p213
aVand give it misconceived  or poorly specified goals.
p214
aa(lp215
VNow you might say, if a computer starts sticking electrodes into people's faces,
p216
aVwe'd just shut it off.
p217
aVA, this is not necessarily so easy to do if we've grown dependent on the system \u2014
p218
aVlike, where is the off switch  to the Internet?
p219
aVB, why haven't the chimpanzees flicked the off switch to humanity,
p220
aVor the Neanderthals?
p221
aVThey certainly had reasons.
p222
aVWe have an off switch,  for example, right here.
p223
aV(Choking)
p224
aVThe reason is that we are  an intelligent adversary;
p225
aVwe can anticipate threats  and plan around them.
p226
aVBut so could a superintelligent agent,
p227
aVand it would be much better  at that than we are.
p228
aVThe point is, we should not be confident that we have this under control here.
p229
aa(lp230
VAnd we could try to make our job a little bit easier by, say,
p231
aVputting the A.I. in a box,
p232
aVlike a secure software environment,
p233
aVa virtual reality simulation from which it cannot escape.
p234
aVBut how confident can we be that the A.I. couldn't find a bug.
p235
aVGiven that merely human hackers find bugs all the time,
p236
aVI'd say, probably not very confident.
p237
aVSo we disconnect the ethernet cable to create an air gap,
p238
aVbut again, like merely human hackers
p239
aVroutinely transgress air gaps using social engineering.
p240
aVRight now, as I speak,
p241
aVI'm sure there is some employee out there somewhere
p242
aVwho has been talked into handing out  her account details
p243
aVby somebody claiming to be from the I.T. department.
p244
aa(lp245
VMore creative scenarios are also possible,
p246
aVlike if you're the A.I.,
p247
aVyou can imagine wiggling electrodes around in your internal circuitry
p248
aVto create radio waves that you can use to communicate.
p249
aVOr maybe you could pretend to malfunction,
p250
aVand then when the programmers open you up to see what went wrong with you,
p251
aVthey look at the source code \u2014 Bam! \u2014
p252
aVthe manipulation can take place.
p253
aVOr it could output the blueprint to a really nifty technology,
p254
aVand when we implement it,
p255
aVit has some surreptitious side effect that the A.I. had planned.
p256
aVThe point here is that we should  not be confident in our ability
p257
aVto keep a superintelligent genie locked up in its bottle forever.
p258
aVSooner or later, it will out.
p259
aa(lp260
VI believe that the answer here is to figure out
p261
aVhow to create superintelligent A.I. such that even if \u2014 when \u2014 it escapes,
p262
aVit is still safe because it is fundamentally on our side
p263
aVbecause it shares our values.
p264
aVI see no way around  this difficult problem.
p265
aa(lp266
VNow, I'm actually fairly optimistic that this problem can be solved.
p267
aVWe wouldn't have to write down  a long list of everything we care about,
p268
aVor worse yet, spell it out  in some computer language
p269
aVlike C++ or Python,
p270
aVthat would be a task beyond hopeless.
p271
aVInstead, we would create an A.I. that uses its intelligence
p272
aVto learn what we value,
p273
aVand its motivation system is constructed in such a way that it is motivated
p274
aVto pursue our values or to perform actions that it predicts we would approve of.
p275
aVWe would thus leverage  its intelligence as much as possible
p276
aVto solve the problem of value-loading.
p277
aa(lp278
VThis can happen,
p279
aVand the outcome could be  very good for humanity.
p280
aVBut it doesn't happen automatically.
p281
aVThe initial conditions  for the intelligence explosion
p282
aVmight need to be set up  in just the right way
p283
aVif we are to have a controlled detonation.
p284
aVThe values that the A.I. has need to match ours,
p285
aVnot just in the familiar context,
p286
aVlike where we can easily check how the A.I. behaves,
p287
aVbut also in all novel contexts that the A.I. might encounter
p288
aVin the indefinite future.
p289
aa(lp290
VAnd there are also some esoteric issues that would need to be solved, sorted out:
p291
aVthe exact details of its decision theory,
p292
aVhow to deal with logical uncertainty and so forth.
p293
aVSo the technical problems that need to be solved to make this work
p294
aVlook quite difficult \u2014
p295
aVnot as difficult as making  a superintelligent A.I.,
p296
aVbut fairly difficult.
p297
aVHere is the worry:
p298
aVMaking superintelligent A.I. is a really hard challenge.
p299
aVMaking superintelligent A.I. that is safe
p300
aVinvolves some additional  challenge on top of that.
p301
aVThe risk is that if somebody figures out how to crack the first challenge
p302
aVwithout also having cracked  the additional challenge
p303
aVof ensuring perfect safety.
p304
aa(lp305
VSo I think that we should work out a solution
p306
aVto the control problem in advance,
p307
aVso that we have it available  by the time it is needed.
p308
aVNow it might be that we cannot solve the entire control problem in advance
p309
aVbecause maybe some elements can only be put in place
p310
aVonce you know the details of the  architecture where it will be implemented.
p311
aVBut the more of the control problem that we solve in advance,
p312
aVthe better the odds that the transition to the machine intelligence era
p313
aVwill go well.
p314
aa(lp315
VThis to me looks like a thing that is well worth doing
p316
aVand I can imagine that if  things turn out okay,
p317
aVthat people a million years from now look back at this century
p318
aVand it might well be that they say that the one thing we did that really mattered
p319
aVwas to get this thing right.
p320
aa(lp321
VThank you.
p322
aa(lp323
V(Applause)
p324
aasS'id'
p325
I2243
sS'title'
p326
VWhat happens when our computers get smarter than we are?
p327
s.