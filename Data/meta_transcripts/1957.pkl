(dp0
S'transcript'
p1
(lp2
(lp3
VIf you remember that first decade of the web,
p4
aVit was really a static place.
p5
aVYou could go online, you could look at pages,
p6
aVand they were put up either by organizations
p7
aVwho had teams to do it
p8
aVor by individuals who were really tech-savvy
p9
aVfor the time.
p10
aVAnd with the rise of social media
p11
aVand social networks in the early 2000s,
p12
aVthe web was completely changed
p13
aVto a place where now the vast majority of content
p14
aVwe interact with is put up by average users,
p15
aVeither in YouTube videos or blog posts
p16
aVor product reviews or social media postings.
p17
aVAnd it's also become a much more interactive place,
p18
aVwhere people are interacting with others,
p19
aVthey're commenting, they're sharing,
p20
aVthey're not just reading.
p21
aa(lp22
VSo Facebook is not the only place you can do this,
p23
aVbut it's the biggest,
p24
aVand it serves to illustrate the numbers.
p25
aVFacebook has 1.2 billion users per month.
p26
aVSo half the Earth's Internet population
p27
aVis using Facebook.
p28
aVThey are a site, along with others,
p29
aVthat has allowed people to create an online persona
p30
aVwith very little technical skill,
p31
aVand people responded by putting huge amounts
p32
aVof personal data online.
p33
aVSo the result is that we have behavioral,
p34
aVpreference, demographic data
p35
aVfor hundreds of millions of people,
p36
aVwhich is unprecedented in history.
p37
aVAnd as a computer scientist,  what this means is that
p38
aVI've been able to build models
p39
aVthat can predict all sorts of hidden attributes
p40
aVfor all of you that you don't even know
p41
aVyou're sharing information about.
p42
aVAs scientists, we use that to help
p43
aVthe way people interact online,
p44
aVbut there's less altruistic applications,
p45
aVand there's a problem in that users don't really
p46
aVunderstand these techniques and how they work,
p47
aVand even if they did, they don't have a lot of control over it.
p48
aVSo what I want to talk to you about today
p49
aVis some of these things that we're able to do,
p50
aVand then give us some ideas of how we might go forward
p51
aVto move some control back into the hands of users.
p52
aa(lp53
VSo this is Target, the company.
p54
aVI didn't just put that logo
p55
aVon this poor, pregnant woman's belly.
p56
aVYou may have seen this anecdote that was printed
p57
aVin Forbes magazine where Target
p58
aVsent a flyer to this 15-year-old girl
p59
aVwith advertisements and coupons
p60
aVfor baby bottles and diapers and cribs
p61
aVtwo weeks before she told her parents
p62
aVthat she was pregnant.
p63
aVYeah, the dad was really upset.
p64
aVHe said, "How did Target figure out
p65
aVthat this high school girl was pregnant
p66
aVbefore she told her parents?"
p67
aVIt turns out that they have the purchase history
p68
aVfor hundreds of thousands of customers
p69
aVand they compute what they  call a pregnancy score,
p70
aVwhich is not just whether or  not a woman's pregnant,
p71
aVbut what her due date is.
p72
aVAnd they compute that
p73
aVnot by looking at the obvious things,
p74
aVlike, she's buying a crib or baby clothes,
p75
aVbut things like, she bought more vitamins
p76
aVthan she normally had,
p77
aVor she bought a handbag
p78
aVthat's big enough to hold diapers.
p79
aVAnd by themselves, those purchases don't seem
p80
aVlike they might reveal a lot,
p81
aVbut it's a pattern of behavior that,
p82
aVwhen you take it in the context  of thousands of other people,
p83
aVstarts to actually reveal some insights.
p84
aVSo that's the kind of thing that we do
p85
aVwhen we're predicting stuff about you on social media.
p86
aVWe're looking for little patterns of behavior that,
p87
aVwhen you detect them among millions of people,
p88
aVlets us find out all kinds of things.
p89
aa(lp90
VSo in my lab and with colleagues,
p91
aVwe've developed mechanisms where we can
p92
aVquite accurately predict things
p93
aVlike your political preference,
p94
aVyour personality score, gender, sexual orientation,
p95
aVreligion, age, intelligence,
p96
aValong with things like
p97
aVhow much you trust the people you know
p98
aVand how strong those relationships are.
p99
aVWe can do all of this really well.
p100
aVAnd again, it doesn't come from what you might
p101
aVthink of as obvious information.
p102
aa(lp103
VSo my favorite example is from this study
p104
aVthat was published this year
p105
aVin the Proceedings of the National Academies.
p106
aVIf you Google this, you'll find it.
p107
aVIt's four pages, easy to read.
p108
aVAnd they looked at just people's Facebook likes,
p109
aVso just the things you like on Facebook,
p110
aVand used that to predict all these attributes,
p111
aValong with some other ones.
p112
aVAnd in their paper they listed the five likes
p113
aVthat were most indicative of high intelligence.
p114
aVAnd among those was liking a page
p115
aVfor curly fries. (Laughter)
p116
aVCurly fries are delicious,
p117
aVbut liking them does not necessarily mean
p118
aVthat you're smarter than the average person.
p119
aVSo how is it that one of the strongest indicators
p120
aVof your intelligence
p121
aVis liking this page
p122
aVwhen the content is totally irrelevant
p123
aVto the attribute that's being predicted?
p124
aVAnd it turns out that we have to look at
p125
aVa whole bunch of underlying theories
p126
aVto see why we're able to do this.
p127
aVOne of them is a sociological theory called homophily,
p128
aVwhich basically says people are friends with people like them.
p129
aVSo if you're smart, you tend to be friends with smart people,
p130
aVand if you're young, you tend to be friends with young people,
p131
aVand this is well established
p132
aVfor hundreds of years.
p133
aVWe also know a lot
p134
aVabout how information spreads through networks.
p135
aVIt turns out things like viral videos
p136
aVor Facebook likes or other information
p137
aVspreads in exactly the same way
p138
aVthat diseases spread through social networks.
p139
aVSo this is something we've studied for a long time.
p140
aVWe have good models of it.
p141
aVAnd so you can put those things together
p142
aVand start seeing why things like this happen.
p143
aVSo if I were to give you a hypothesis,
p144
aVit would be that a smart guy started this page,
p145
aVor maybe one of the first people who liked it
p146
aVwould have scored high on that test.
p147
aVAnd they liked it, and their friends saw it,
p148
aVand by homophily, we know that he probably had smart friends,
p149
aVand so it spread to them,  and some of them liked it,
p150
aVand they had smart friends,
p151
aVand so it spread to them,
p152
aVand so it propagated through the network
p153
aVto a host of smart people,
p154
aVso that by the end, the action
p155
aVof liking the curly fries page
p156
aVis indicative of high intelligence,
p157
aVnot because of the content,
p158
aVbut because the actual action of liking
p159
aVreflects back the common attributes
p160
aVof other people who have done it.
p161
aa(lp162
VSo this is pretty complicated stuff, right?
p163
aVIt's a hard thing to sit down and explain
p164
aVto an average user, and even if you do,
p165
aVwhat can the average user do about it?
p166
aVHow do you know that  you've liked something
p167
aVthat indicates a trait for you
p168
aVthat's totally irrelevant to the content of what you've liked?
p169
aVThere's a lot of power that users don't have
p170
aVto control how this data is used.
p171
aVAnd I see that as a real  problem going forward.
p172
aa(lp173
VSo I think there's a couple paths
p174
aVthat we want to look at
p175
aVif we want to give users some control
p176
aVover how this data is used,
p177
aVbecause it's not always going to be used
p178
aVfor their benefit.
p179
aVAn example I often give is that,
p180
aVif I ever get bored being a professor,
p181
aVI'm going to go start a company
p182
aVthat predicts all of these attributes
p183
aVand things like how well you work in teams
p184
aVand if you're a drug user, if you're an alcoholic.
p185
aVWe know how to predict all that.
p186
aVAnd I'm going to sell reports
p187
aVto H.R. companies and big businesses
p188
aVthat want to hire you.
p189
aVWe totally can do that now.
p190
aVI could start that business tomorrow,
p191
aVand you would have absolutely no control
p192
aVover me using your data like that.
p193
aVThat seems to me to be a problem.
p194
aa(lp195
VSo one of the paths we can go down
p196
aVis the policy and law path.
p197
aVAnd in some respects, I think that that would be most effective,
p198
aVbut the problem is we'd actually have to do it.
p199
aVObserving our political process in action
p200
aVmakes me think it's highly unlikely
p201
aVthat we're going to get a bunch of representatives
p202
aVto sit down, learn about this,
p203
aVand then enact sweeping changes
p204
aVto intellectual property law in the U.S.
p205
aVso users control their data.
p206
aa(lp207
VWe could go the policy route,
p208
aVwhere social media companies say,
p209
aVyou know what? You own your data.
p210
aVYou have total control over how it's used.
p211
aVThe problem is that the revenue models
p212
aVfor most social media companies
p213
aVrely on sharing or exploiting  users' data in some way.
p214
aVIt's sometimes said of Facebook that the users
p215
aVaren't the customer, they're the product.
p216
aVAnd so how do you get a company
p217
aVto cede control of their main asset
p218
aVback to the users?
p219
aVIt's possible, but I don't think it's something
p220
aVthat we're going to see change quickly.
p221
aa(lp222
VSo I think the other path
p223
aVthat we can go down that's going to be more effective
p224
aVis one of more science.
p225
aVIt's doing science that allowed us to develop
p226
aVall these mechanisms for computing
p227
aVthis personal data in the first place.
p228
aVAnd it's actually very similar research
p229
aVthat we'd have to do
p230
aVif we want to develop mechanisms
p231
aVthat can say to a user,
p232
aV"Here's the risk of that action you just took."
p233
aVBy liking that Facebook page,
p234
aVor by sharing this piece of personal information,
p235
aVyou've now improved my ability
p236
aVto predict whether or not you're using drugs
p237
aVor whether or not you get along well in the workplace.
p238
aVAnd that, I think, can affect whether or not
p239
aVpeople want to share something,
p240
aVkeep it private, or just keep it offline altogether.
p241
aVWe can also look at things like
p242
aVallowing people to encrypt data that they upload,
p243
aVso it's kind of invisible and worthless
p244
aVto sites like Facebook
p245
aVor third party services that access it,
p246
aVbut that select users who the person who posted it
p247
aVwant to see it have access to see it.
p248
aVThis is all super exciting research
p249
aVfrom an intellectual perspective,
p250
aVand so scientists are going to be willing to do it.
p251
aVSo that gives us an advantage over the law side.
p252
aa(lp253
VOne of the problems that people bring up
p254
aVwhen I talk about this is, they say,
p255
aVyou know, if people start keeping all this data private,
p256
aVall those methods that you've been developing
p257
aVto predict their traits are going to fail.
p258
aVAnd I say, absolutely, and for me, that's success,
p259
aVbecause as a scientist,
p260
aVmy goal is not to infer information about users,
p261
aVit's to improve the way people interact online.
p262
aVAnd sometimes that involves inferring things about them,
p263
aVbut if users don't want me to use that data,
p264
aVI think they should have the right to do that.
p265
aVI want users to be informed and consenting
p266
aVusers of the tools that we develop.
p267
aa(lp268
VAnd so I think encouraging this kind of science
p269
aVand supporting researchers
p270
aVwho want to cede some of that control back to users
p271
aVand away from the social media companies
p272
aVmeans that going forward, as these tools evolve
p273
aVand advance,
p274
aVmeans that we're going to have an educated
p275
aVand empowered user base,
p276
aVand I think all of us can agree
p277
aVthat that's a pretty ideal way to go forward.
p278
aa(lp279
VThank you.
p280
aa(lp281
V(Applause)
p282
aasS'id'
p283
I1957
sS'title'
p284
VYour social media "likes" expose more than you think
p285
s.